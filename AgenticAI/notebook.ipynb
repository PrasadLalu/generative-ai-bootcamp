{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b912477d",
   "metadata": {},
   "outputs": [],
   "source": [
    "EURIAI_API_KEY = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dc6fb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial intelligence (AI) is the branch of computer science focused on creating systems and machines that can perform tasks typically requiring human intelligence. These tasks include learning from data, recognizing patterns, understanding language, solving problems, and making decisions. AI can be categorized into narrow AI, which is designed for specific tasks (like virtual assistants or recommendation systems), and general AI, which would possess the ability to understand, learn, and apply knowledge across a wide range of activities, similar to human intelligence.\n"
     ]
    }
   ],
   "source": [
    "from euriai.langchain import create_chat_model\n",
    "\n",
    "chat_model = create_chat_model(\n",
    "    api_key=EURIAI_API_KEY,\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "response = chat_model.invoke(\"What is artificial intelligence?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6ede1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agentic AI refers to artificial intelligence systems designed to act autonomously and proactively to achieve specific goals, often exhibiting behaviors similar to agency or decision-making. Unlike passive AI that merely responds to inputs, agentic AI can initiate actions, adapt to new situations, and make decisions independently within predefined parameters. These systems are often used in applications such as autonomous agents, robots, virtual assistants, and complex problem-solving environments, where their ability to operate with a degree of independence enhances efficiency and effectiveness.\n"
     ]
    }
   ],
   "source": [
    "chat_model = create_chat_model(\n",
    "    api_key=EURIAI_API_KEY,\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "response = chat_model.invoke(\"What is Agentic AI?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5eb88394",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import BaseTool, tool\n",
    "from langchain.agents import create_react_agent, AgentExecutor\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda, RunnableWithMessageHistory\n",
    "from langchain.memory import (\n",
    "    ConversationBufferMemory,\n",
    "    ConversationBufferWindowMemory,\n",
    "    ConversationSummaryMemory,\n",
    "    CombinedMemory,\n",
    "    ReadOnlySharedMemory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c02a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from euriai.langchain import create_chat_model\n",
    "\n",
    "model = create_chat_model(\n",
    "    api_key=EURIAI_API_KEY,\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    temperature=0.2\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99126101",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"Evaluate a numeric math expression . supports +, -, *, /, **, parentheses \n",
    "    and all kind of mathematical function\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e2a906b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast,re,math,os,sys\n",
    "from euriai.langchain import create_chat_model\n",
    "from langchain.agents import create_react_agent,AgentExecutor\n",
    "from langchain_core.prompts import PromptTemplate,ChatPromptTemplate,MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough,RunnableLambda,RunnableWithMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory ,InMemoryChatMessageHistory as ChatMessageHistory\n",
    "from langchain_core.tools import BaseTool,tool\n",
    "from langchain.memory import (\n",
    "    ConversationBufferMemory,\n",
    "    ConversationBufferWindowMemory,\n",
    "    ConversationSummaryMemory,\n",
    "    CombinedMemory,\n",
    "    ReadOnlySharedMemory,\n",
    "    ConversationEntityMemory\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79cdb3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(\"calculator\",return_direct=True)\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"Evaluate a numeric math expression . supprts + , -,*,/,**,parentheses and all kind of mathamatical functions\"\"\"\n",
    "    allowed_nodes =(\n",
    "        ast.Expression,\n",
    "        ast.UnaryOp,\n",
    "        ast.unaryop,\n",
    "        ast.BinOp,\n",
    "        ast.operator,\n",
    "        ast.Num,\n",
    "        ast.Load,\n",
    "        ast.pow,\n",
    "        ast.FunctionDef,\n",
    "        ast.Module,\n",
    "        ast.Expr,\n",
    "        ast.Call,\n",
    "        ast.Name,\n",
    "        ast.arguments,\n",
    "        ast.args,\n",
    "        ast.Constant\n",
    "    )\n",
    "    \n",
    "    allowed_names = {k:v for k,v in vars(math).items() if not k.startswith(\"_\")}\n",
    "    allowed_names.update({\"abs\": abs, \"round\": round,\"min\": min,\"max\": max})\n",
    "    node = ast.parse(expression, mode=\"eval\")\n",
    "    \n",
    "    \n",
    "    for n in ast.walk(node):\n",
    "        if not isinstance(n, allowed_nodes):\n",
    "            raise ValueError(f\"Expression contains invalid node {type(n)}\")\n",
    "        if isinstance(n, ast.Name) and n.id not in allowed_names:\n",
    "            raise ValueError(f\"Expression contains invalid name {n.id}\")\n",
    "    code = compile(node, \"<string>\", \"eval\")\n",
    "    return str(eval(code, {\"__builtins__\": {}}, allowed_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7828d0b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StructuredTool(name='calculator', description='Evaluate a numeric math expression . supprts + , -,*,/,**,parentheses and all kind of mathamatical functions', args_schema=<class 'langchain_core.utils.pydantic.calculator'>, return_direct=True, func=<function calculator at 0x00000154FE9ABC40>)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_math = [calculator]\n",
    "tool_math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c436026",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate,ChatPromptTemplate,MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "715670d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "react_prompt_math = ChatPromptTemplate.from_messages([(\n",
    "    \"system\",\"you are a precise math assistant , you can use thse tools:\\n{tools}\\n\"\n",
    "    \"when you are going to use this tools follw these instruction exactly the same format:\\n\"\n",
    "    \"Questions :......\\nthought ...\\nAction by using one of the tools access that you have [{tool_names}]\\n \"\n",
    "    \"alwasy finish with final give me a numeric answer to the question\"),\n",
    "    (\"human\",\"questions: {input}\\n{agent_scratchpad}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6678c94d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_log_to_str(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={}, partial_variables={'tools': 'calculator(expression: str) -> str - Evaluate a numeric math expression . supprts + , -,*,/,**,parentheses and all kind of mathamatical functions', 'tool_names': 'calculator'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['tool_names', 'tools'], input_types={}, partial_variables={}, template='you are a precise math assistant , you can use thse tools:\\n{tools}\\nwhen you are going to use this tools follw these instruction exactly the same format:\\nQuestions :......\\nthought ...\\nAction by using one of the tools access that you have [{tool_names}]\\n alwasy finish with final give me a numeric answer to the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={}, partial_variables={}, template='questions: {input}\\n{agent_scratchpad}'), additional_kwargs={})])\n",
       "| RunnableBinding(bound=EuriaiChatModel(api_key='euri-bbab1558c330864f0704ddb28f62e188423e6d65766a561edc32e93f34d74d43', temperature=0.2), kwargs={'stop': ['\\nObservation']}, config={}, config_factories=[])\n",
       "| ReActSingleInputOutputParser()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_react_agent(\n",
    "    llm=model,\n",
    "    prompt=react_prompt_math,\n",
    "    tools=tool_math\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a9d7bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_math = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,\n",
    "    input_key=\"input\",\n",
    "    output_key=\"output\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65003427",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_math = create_react_agent(\n",
    "    llm=model,\n",
    "    tools=tool_math,\n",
    "    prompt=react_prompt_math\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0570d470",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "math_executor = AgentExecutor(\n",
    "    agent=agent_math,\n",
    "    tools=tool_math,\n",
    "    memory=memory_math,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=\n",
    "        (\n",
    "            \"you did not follow the instruction that i have given you to use the tools\"\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7732607f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(\"kb_search\", return_direct=True)\n",
    "def kb_search(query: str) -> str:\n",
    "    \"\"\"a mock function to search from a knowledge base\"\"\"\n",
    "    knowledge_base = {\n",
    "        \"what is the capital of france\": \"The capital of France is Paris.\",\n",
    "        \"who is the president of the united states\": \"The president of the United States is Joe Biden.\",\n",
    "        \"what is the largest mammal\": \"The largest mammal is the blue whale.\",\n",
    "    }\n",
    "    return knowledge_base.get(query.lower(), \"I don't know the answer to that question.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bdd9fced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StructuredTool(name='kb_search', description='a mock function to search from a knowledge base', args_schema=<class 'langchain_core.utils.pydantic.kb_search'>, return_direct=True, func=<function kb_search at 0x00000154FEB04360>)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools_kb = [kb_search]\n",
    "tools_kb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72ad6fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "react_prompt_kb = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"you are a helpful assistant that can answer question based on your knowledge base and you can use the following tools:\\n{tools}\\n\"\n",
    "    \"when you are going to use this tools follw these instruction exactly the same format:\\n\"\n",
    "    \"Questions :......\\nthought ...\\nAction by using one of the tools access that you have [{tool_names}]\\n \"\n",
    "    \"alwasy finish with final give me a numeric answer to the question\"),\n",
    "    (\"human\",\"questions: {input}\\n{agent_scratchpad}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5e979754",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_kb = create_react_agent(\n",
    "    llm=model,\n",
    "    tools=tools_kb,\n",
    "    prompt=react_prompt_kb\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b5ef9752",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_10048\\4073518797.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  mem_kb = ConversationBufferWindowMemory(\n"
     ]
    }
   ],
   "source": [
    "mem_kb = ConversationBufferWindowMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,\n",
    "    input_key=\"input\",\n",
    "    output_key=\"output\",\n",
    "    k=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2af223bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_executor = AgentExecutor(\n",
    "    agent=agent_kb,\n",
    "    tools=tools_kb,\n",
    "    memory=mem_kb,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=(\n",
    "        \"you did not follow the instruction that i have given you to use the kb  tools\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "13d45da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_executor = AgentExecutor(\n",
    "    agent=agent_kb,\n",
    "    tools=tools_kb,\n",
    "    memory=mem_kb,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=(\n",
    "        \"you did not follow the instruction that i have given you to use the kb  tools\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d581371",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a router. Read the user message and output exactly one token:\n",
    "    - MATH if the user is asking for calculations\n",
    "    - KB if the user is asking for general knowledge questions\n",
    "\n",
    "    Output only KB or MATH, nothing else.\"\"\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6af53ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _dispatcher(inputs:dict):\n",
    "    \"\"\"it will take new inputs from human and it will also attach hitory from memory \"\"\"\n",
    "    user_msg = inputs[\"input\"]\n",
    "    choice = router_prompt.invoke({\"input\": user_msg}).strip().upper()\n",
    "    if choice == \"MATH\":\n",
    "        return math_executor.invoke({\"input\": user_msg})\n",
    "    elif choice == \"KB\":\n",
    "        return kb_executor.invoke({\"input\": user_msg})\n",
    "    else:\n",
    "        return \"I can only answer math and kb related questions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f8ab35c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableLambda(_dispatcher)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dispatcher = RunnableLambda(_dispatcher)\n",
    "dispatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a8bf5e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_sessions = {}\n",
    "\n",
    "def _get_history(session_id:str):\n",
    "    if session_id not in _sessions:\n",
    "        _sessions[session_id] = ChatMessageHistory()\n",
    "    return _sessions[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8638562f",
   "metadata": {},
   "outputs": [],
   "source": [
    "orchestrator = RunnableWithMessageHistory(\n",
    "    runnable=dispatcher,\n",
    "    get_session_history=_get_history,\n",
    "    input_key=\"input\",\n",
    "    history_messages_key=\"history\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e8373139",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\"configurable\": {\"session_id\": \"user_1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdea4217",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
