{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f62f3fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bee0a8",
   "metadata": {},
   "source": [
    "### Define OpenAI Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "486ee7e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Generative AI refers to a class of artificial intelligence models and systems designed to create content, such as text, images, audio, and even video, by learning patterns from existing data. Unlike traditional AI, which focuses on recognition and classification tasks (like identifying objects in images), generative AI generates new data instances that resemble the training data it was exposed to.\\n\\nKey characteristics and technologies associated with generative AI include:\\n\\n1. **Learning from Data**: Generative AI models are trained on large datasets to understand the underlying patterns and structures. This training allows them to produce new, similar samples.\\n\\n2. **Variational Autoencoders (VAEs)** and **Generative Adversarial Networks (GANs)**: Two of the most common architectures used in generative AI. VAEs learn an encoding of the data distribution, while GANs involve a generator that creates new data and a discriminator that evaluates its authenticity.\\n\\n3. **Natural Language Processing (NLP)**: Models like OpenAI’s GPT (Generative Pre-trained Transformer) generate human-like text based on prompts. They can write stories, answer questions, and even draft emails.\\n\\n4. **Image Generation**: Tools like DALL-E and Stable Diffusion can generate images from textual descriptions, showcasing the capability to create visual content creatively.\\n\\n5. **Content Creation**: Generative AI is used in various applications such as art, music composition, game design, and even drug discovery, where the generation of novel molecules is crucial.\\n\\n6. **Ethical Considerations**: The rise of generative AI brings challenges, including issues related to copyright, misinformation, and the potential for misuse in creating deceptive content.\\n\\nIn summary, generative AI represents a transformative approach in the field of artificial intelligence, enabling the creation of original content across diverse domains.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 363, 'prompt_tokens': 13, 'total_tokens': 376, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C7zoCl2FGB2i3JYK0EuzMwm4modw4', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--53cb3c8c-497e-417e-b218-41ba2f2336ba-0', usage_metadata={'input_tokens': 13, 'output_tokens': 363, 'total_tokens': 376, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4o-mini')\n",
    "llm.invoke('What is generative AI?')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90423789",
   "metadata": {},
   "source": [
    "### Define Groq Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e06c2a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='**Generative AI** refers to artificial intelligence systems that can *create* new content—text, images, audio, video, code, designs, and more—rather than merely recognizing or classifying existing data. These models learn patterns and structures from large datasets and then use that knowledge to generate novel outputs that resemble the training data but are not direct copies.\\n\\n### Core Characteristics\\n\\n| Feature | Explanation |\\n|---------|-------------|\\n| **Data‑driven learning** | Trained on massive corpora (e.g., books, photos, music). |\\n| **Probabilistic generation** | Produces content by sampling from learned probability distributions. |\\n| **Creativity & variation** | Able to produce many different outputs for the same prompt. |\\n| **Context awareness** | Maintains coherence over sentences, paragraphs, or longer sequences. |\\n\\n### Common Generative Models\\n\\n| Model | Domain | Notable Example |\\n|-------|--------|-----------------|\\n| **Transformers (e.g., GPT‑4, BERT‑style)** | Text | ChatGPT, GPT‑4 |\\n| **Diffusion models (e.g., Stable Diffusion, DALL·E 2)** | Images | DALL·E 2, Midjourney |\\n| **GANs (e.g., StyleGAN)** | Images & video | DeepFakes, synthetic portraits |\\n| **VAE / Autoregressive models** | Audio, music | Jukebox, WaveNet |\\n| **Reinforcement‑Learning‑based agents** | Interactive content | AI Dungeon, OpenAI’s Muse |\\n\\n### How It Works (Simplified)\\n\\n1. **Training Phase**  \\n   - The model ingests a large dataset.  \\n   - It learns to predict the next token/element (word, pixel, note).  \\n   - Loss functions (e.g., cross‑entropy, mean‑squared error) guide the weights to capture the distribution.\\n\\n2. **Generation Phase**  \\n   - Given a prompt or seed, the model samples from its learned distribution.  \\n   - Techniques such as *temperature*, *top‑k*, or *nucleus* sampling control randomness.  \\n   - The output is a sequence that statistically aligns with the training data but is new.\\n\\n### Applications\\n\\n| Field | Use‑case |\\n|-------|----------|\\n| **Creative arts** | Writing stories, poems, song lyrics, visual art. |\\n| **Product design** | Generating 3D models, logos, UI mockups. |\\n| **Content creation** | Drafting emails, reports, marketing copy. |\\n| **Education** | Generating practice problems, explanatory text. |\\n| **Entertainment** | Procedural game content, virtual characters. |\\n\\n### Ethical & Practical Considerations\\n\\n- **Bias & Fairness** – Models may reproduce biases present in training data.  \\n- **Authenticity & Attribution** – Generated content can be hard to distinguish from human‑produced work.  \\n- **Copyright** – Training data may include copyrighted material.  \\n- **Misuse** – Deepfakes, disinformation, and automated phishing.\\n\\n---\\n\\n**Bottom line:** Generative AI is a branch of machine learning that empowers computers to *create* new, original content by learning patterns from vast amounts of data, enabling a wide array of creative, productive, and interactive applications.', additional_kwargs={'reasoning_content': 'We need to answer the question: \"What is generative AI?\" Provide a concise explanation, maybe examples. The user didn\\'t specify format. Just answer.'}, response_metadata={'token_usage': {'completion_tokens': 721, 'prompt_tokens': 77, 'total_tokens': 798, 'completion_time': 0.643488253, 'prompt_time': 0.0050336, 'queue_time': 0.08703068, 'total_time': 0.648521853}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_a5ac2a5d7b', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--1305d1b5-262d-493c-8d54-2903bdd62a34-0', usage_metadata={'input_tokens': 77, 'output_tokens': 721, 'total_tokens': 798})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# llm = ChatGroq(model='gemma2-9b-it')\n",
    "# llm = ChatGroq(model='llama3-8b-8192')\n",
    "llm = ChatGroq(model='openai/gpt-oss-20b')\n",
    "\n",
    "llm.invoke('What is generative AI?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e456f2",
   "metadata": {},
   "source": [
    "### Define Gemini Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c6daf57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='**Generative AI** refers to a category of artificial intelligence models that are designed to **create new, original content** rather than just analyzing or classifying existing data. Unlike traditional AI that might identify a cat in an image (discriminative AI), generative AI can *produce* a new image of a cat that has never existed before.\\n\\nHere\\'s a breakdown of what that means:\\n\\n1.  **Creation, Not Just Classification:**\\n    *   **Discriminative AI:** Learns to distinguish between different categories (e.g., \"Is this a cat or a dog?\").\\n    *   **Generative AI:** Learns the underlying patterns and structures of data to generate new instances that resemble the training data but are not exact copies.\\n\\n2.  **How it Works (Simplified):**\\n    *   **Training Data:** Generative AI models are trained on vast datasets of existing content (text, images, audio, code, etc.).\\n    *   **Pattern Learning:** During training, the model learns the statistical regularities, relationships, and underlying \"rules\" that govern the data. For example, an image generation model learns what makes a face look like a face, or how light interacts with objects. A language model learns grammar, syntax, common phrases, and factual information.\\n    *   **Generation:** Once trained, the model can take a prompt (text, image, or other input) and use its learned patterns to produce novel output that fits the prompt and is consistent with the style and characteristics of its training data.\\n\\n3.  **Key Characteristics:**\\n    *   **Novelty:** Produces genuinely new content that didn\\'t exist before.\\n    *   **Coherence & Realism:** The generated content often looks, sounds, or reads very much like human-created content.\\n    *   **Diversity:** Can generate a wide range of variations based on a single prompt.\\n    *   **Adaptability:** Can be fine-tuned for specific tasks or styles.\\n\\n4.  **Common Types and Examples:**\\n    *   **Large Language Models (LLMs):** Generate human-like text.\\n        *   **Examples:** OpenAI\\'s GPT-3/GPT-4, Google\\'s Bard/Gemini, Meta\\'s Llama.\\n        *   **Applications:** Writing articles, summarizing text, answering questions, generating code, translating languages, creating chatbots.\\n    *   **Diffusion Models:** Excellent at generating high-quality images and other media.\\n        *   **Examples:** Stability AI\\'s Stable Diffusion, Midjourney, OpenAI\\'s DALL-E.\\n        *   **Applications:** Creating art, designing product mockups, generating realistic photos from text descriptions, image editing.\\n    *   **Generative Adversarial Networks (GANs):** An older but still relevant architecture, particularly for image generation, where two neural networks (a generator and a discriminator) compete to produce realistic outputs.\\n        *   **Applications:** Creating realistic faces, style transfer, generating synthetic data.\\n    *   **Other Modalities:** Generative AI can also create audio (music, voice synthesis), video, 3D models, and even synthetic data for scientific research.\\n\\n5.  **Why is it Significant?**\\n    *   **Democratization of Creativity:** Allows individuals without specialized skills to create high-quality content.\\n    *   **Automation & Efficiency:** Speeds up content creation, design processes, and code development.\\n    *   **New Possibilities:** Enables entirely new forms of art, entertainment, and problem-solving.\\n    *   **Personalization:** Can generate highly customized content for individuals.\\n\\n6.  **Challenges and Ethical Considerations:**\\n    *   **Bias:** Models can inherit and amplify biases present in their training data.\\n    *   **Misinformation & Deepfakes:** The ability to generate realistic fake content (images, audio, video) poses risks for spreading misinformation.\\n    *   **Copyright & Ownership:** Questions arise about who owns the content generated by AI.\\n    *   **Job Displacement:** Potential impact on creative and knowledge-based industries.\\n    *   **Environmental Impact:** Training large models requires significant computational resources and energy.\\n    *   **Hallucinations:** LLMs can sometimes generate plausible-sounding but factually incorrect information.\\n\\nIn essence, Generative AI represents a powerful leap in AI capabilities, moving beyond analysis to active creation, with profound implications across nearly every industry.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--9eba937e-5fbb-413c-b744-c0b2758d4b11-0', usage_metadata={'input_tokens': 6, 'output_tokens': 2193, 'total_tokens': 2199, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 1261}})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model='gemini-2.5-flash', temperature=0)\n",
    "llm.invoke('What is generative AI?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812ed600",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.18)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
