{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b2cda45",
   "metadata": {},
   "source": [
    "## GROQ LLM Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d4ddcce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "577fa700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000028A6AD5BC80>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000028A6B1482F0>, model_name='openai/gpt-oss-20b', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(model='openai/gpt-oss-20b')\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd307cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='**Agentic AI** – short for *“agentic artificial intelligence”* – is a class of AI systems that possess **agency**: the capacity to act, make choices, and pursue goals in a self‑directed way.\\n\\n---\\n\\n## 1. Core Characteristics\\n\\n| Feature | What it means | Why it matters |\\n|---------|---------------|----------------|\\n| **Goal‑oriented** | The system has explicit or learned objectives it tries to achieve. | Enables purposeful behavior rather than just reactive pattern matching. |\\n| **Autonomy** | It can initiate actions without external prompts, and decide *when* and *how* to act. | Allows the system to operate in dynamic, real‑world environments. |\\n| **Planning & Reasoning** | It can model the world, predict outcomes, and choose a sequence of actions to reach a goal. | Gives the system foresight and flexibility. |\\n| **Learning & Adaptation** | It updates its internal model or policy based on experience. | Keeps the agent effective as environments change. |\\n| **Self‑monitoring & Self‑improvement** | It can evaluate its own performance and modify its strategies. | Enables continuous improvement and resilience. |\\n\\n---\\n\\n## 2. How It Differs From Other AI Paradigms\\n\\n| Paradigm | Typical Focus | Agentic AI? |\\n|----------|---------------|-------------|\\n| **Reactive/Rule‑Based Systems** | Execute pre‑defined responses to stimuli. | No – no planning or goal pursuit. |\\n| **Supervised Learning Models** | Learn mappings from inputs to outputs. | No – they don’t choose actions or set goals. |\\n| **Reinforcement Learning (RL)** | Learn to maximize a reward signal. | Yes – RL is the most common foundation for agentic AI, but agentic AI also includes higher‑level planning and autonomy. |\\n| **Generative Models** | Produce data (images, text). | No – they generate content but don’t act in the world. |\\n\\n---\\n\\n## 3. Typical Examples\\n\\n| Domain | Agentic AI in Action |\\n|--------|----------------------|\\n| **Autonomous Vehicles** | Plan routes, avoid obstacles, make split‑second decisions. |\\n| **Robotics** | Navigate homes, perform tasks, adapt to new objects. |\\n| **Virtual Assistants** | Schedule meetings, learn preferences, suggest actions. |\\n| **Game AI** | NPCs that strategize, adapt to player behavior, pursue in‑game goals. |\\n| **Personalized Recommendation Engines** | Continually update models to match evolving user preferences. |\\n\\n---\\n\\n## 4. Research & Technical Foundations\\n\\n| Area | Key Concepts |\\n|------|--------------|\\n| **Decision Theory & MDPs** | Formalizing goals, actions, and state transitions. |\\n| **Hierarchical RL** | Decomposing complex tasks into sub‑goals. |\\n| **Planning Algorithms** | A*, Monte Carlo Tree Search, POMDPs. |\\n| **Meta‑Learning** | Learning how to learn new tasks quickly. |\\n| **Value Alignment & Safety** | Ensuring the agent’s goals align with human values. |\\n\\n---\\n\\n## 5. Why It Matters\\n\\n1. **Practical Utility** – Agentic AI powers the next generation of autonomous systems that can operate without constant human oversight.\\n2. **Ethical & Societal Impact** – As agents gain more autonomy, questions of responsibility, bias, and control become critical.\\n3. **Alignment Research** – The more agentic an AI, the higher the stakes for ensuring it behaves safely and beneficially.\\n\\n---\\n\\n## 6. Quick Takeaway\\n\\n*Agentic AI* = an AI that **chooses** *what* to do, **how** to do it, and **why** it does it—based on goals, planning, and learning. It moves beyond “reactive” or “output‑only” systems and enters the realm of autonomous, purposeful agents.' additional_kwargs={'reasoning_content': 'The user asks: \"What is Agentic AI?\" They want an explanation. We should define agentic AI, its characteristics, differences from other AI paradigms, examples, implications, maybe mention self-directedness, autonomy, goals, etc. Provide clear, concise answer. Possibly mention that agentic AI is AI with agency: ability to take actions, make decisions, pursue goals, etc. Might also discuss the concept in context of AGI, autonomy, and alignment. Also mention that it\\'s not just reactive but proactive. Provide examples: autonomous vehicles, personal assistants, AI agents in games, etc. Also mention that agentic AI is about having an internal model of the world, planning, etc. Might mention research in AI alignment, value alignment, and the risk of misaligned agentic AI.\\n\\nLet\\'s produce a well-structured answer.'} response_metadata={'token_usage': {'completion_tokens': 994, 'prompt_tokens': 77, 'total_tokens': 1071, 'completion_time': 0.897078817, 'prompt_time': 0.032171902, 'queue_time': 0.216450657, 'total_time': 0.929250719}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_fd68d84dd3', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None} id='run--fdbfb536-1d8f-4340-b42f-c10c60aee1e3-0' usage_metadata={'input_tokens': 77, 'output_tokens': 994, 'total_tokens': 1071}\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke('What is Agentic AI?')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c165486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000028A721D2C00>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000028A7385D0A0>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "chat_model = init_chat_model('groq:gemma2-9b-it')\n",
    "chat_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b87bcbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Agentic AI refers to a type of artificial intelligence that is **autonomous and goal-oriented**.\\n\\nHere's a breakdown:\\n\\n* **Autonomous:** Agentic AI systems can act independently, making decisions and taking actions without constant human intervention.\\n\\n* **Goal-Oriented:** These AI systems are designed with specific objectives in mind. They work towards achieving these goals through their actions and interactions with their environment.\\n\\n**Key characteristics of Agentic AI:**\\n\\n* **Reactivity:** Responds to changes in its environment.\\n* **Proactivity:** Takes initiative and acts even without explicit instructions.\\n* **Learning:** Adapts and improves its performance over time based on experience.\\n* **Planning:** Develops strategies and sequences of actions to achieve its goals.\\n* **Social Interaction:** Can interact and collaborate with other agents (AI or human).\\n\\n**Examples of Agentic AI:**\\n\\n* **Self-driving cars:** Navigate roads, make decisions about speed and lane changes, and avoid obstacles.\\n* **Robotics:** Industrial robots performing repetitive tasks, or humanoid robots interacting with humans.\\n* **Game AI:** Non-player characters (NPCs) in video games that exhibit intelligent behavior and react to player actions.\\n* **Virtual Assistants:** Like Siri or Alexa, can perform tasks, answer questions, and learn user preferences.\\n\\n**Benefits of Agentic AI:**\\n\\n* **Automation:** Can handle complex tasks efficiently and autonomously.\\n* **Improved efficiency and productivity:** Can work 24/7 without breaks.\\n* **Enhanced decision-making:** Can analyze data and make informed decisions.\\n* **New possibilities:** Enables the creation of novel applications and experiences.\\n\\n**Challenges of Agentic AI:**\\n\\n* **Safety and reliability:** Ensuring that autonomous systems operate safely and reliably is crucial.\\n* **Ethical considerations:** Addressing issues like bias, accountability, and transparency in AI decision-making.\\n* **Control and oversight:** Establishing mechanisms for human control and intervention when necessary.\\n* **Job displacement:** The potential for automation to displace human workers.\\n\\nAgentic AI is a rapidly evolving field with the potential to transform many aspects of our lives. It's essential to continue researching and developing these technologies responsibly, addressing the associated challenges and ensuring that they benefit society as a whole.\\n\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 470, 'prompt_tokens': 15, 'total_tokens': 485, 'completion_time': 0.854545455, 'prompt_time': 0.001248511, 'queue_time': 0.246261789, 'total_time': 0.855793966}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None} id='run--366c7062-808c-45d5-a13c-74d54d5f14ea-0' usage_metadata={'input_tokens': 15, 'output_tokens': 470, 'total_tokens': 485}\n"
     ]
    }
   ],
   "source": [
    "response = chat_model.invoke('What is Agentic AI?')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47f15d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Agentic AI – the “Self‑Acting” Side of Artificial Intelligence\n",
      "\n",
      "### 1.  What “Agentic” Means\n",
      "\n",
      "The word *agentic* comes from the Latin *agens* (“doing”) and the philosophical concept of **agency**: the capacity of an entity to initiate, plan, and execute actions toward goals.  In human psychology, agency is one half of the “agency–communion” dichotomy that describes how we see ourselves as either goal‑driven (agentic) or relational (communicative).  \n",
      "\n",
      "When we talk about **Agentic AI** we are borrowing that idea for machines: an AI that is not merely a tool that reacts to human input, but one that can:\n",
      "\n",
      "| Feature | Reactive / Tool‑like AI | Agentic AI |\n",
      "|---------|------------------------|------------|\n",
      "| **Goal‑setting** | None (or pre‑set by programmer) | Can generate or revise its own goals |\n",
      "| **Planning** | Executes a single instruction or a fixed script | Builds multi‑step plans, optimizes for long‑term success |\n",
      "| **Learning** | Typically one‑off or supervised | Continually learns from experience, adapts strategy |\n",
      "| **Initiation** | Requires explicit prompt | Can decide *when* to act, even without a human cue |\n",
      "| **Self‑representation** | None | Maintains an internal model of its own state, resources, and constraints |\n",
      "| **Self‑improvement** | Rare, often manual | May modify its own code or architecture (within safety limits) |\n",
      "\n",
      "In short, agentic AI is **autonomous** *and* **purpose‑driven**.\n",
      "\n",
      "---\n",
      "\n",
      "### 2.  Where the Term Appears\n",
      "\n",
      "| Field | How “agentic” is used | Example |\n",
      "|-------|----------------------|---------|\n",
      "| **AI Research** | Refers to *agent* in the classic sense of an autonomous decision‑maker (e.g., reinforcement‑learning agents). | DeepMind’s AlphaGo, OpenAI’s DALL‑E “agent” that can generate images from prompts. |\n",
      "| **Robotics** | Autonomous robots that plan, navigate, and act in the real world. | Boston Dynamics’ Atlas, autonomous delivery drones. |\n",
      "| **Human‑AI Interaction** | AI that can negotiate, propose, or persuade. | GPT‑4 acting as a “personal assistant” that sets reminders, drafts emails, and suggests actions. |\n",
      "| **Ethics & Governance** | Discusses the risks of AI that can set its own goals. | Papers on “Artificial General Intelligence” and “AI alignment” often talk about the *agentic* nature of the system. |\n",
      "\n",
      "---\n",
      "\n",
      "### 3.  Core Characteristics of Agentic AI\n",
      "\n",
      "| Characteristic | Why It Matters | Typical Implementation |\n",
      "|----------------|----------------|------------------------|\n",
      "| **Goal Generation** | Allows the system to pursue objectives beyond its initial programming. | Reward shaping in RL; hierarchical policy learning. |\n",
      "| **Planning & Decision‑Making** | Enables multi‑step reasoning, trade‑offs, and foresight. | Monte Carlo Tree Search, symbolic planners, neural‑symbolic hybrids. |\n",
      "| **Learning from Interaction** | Keeps the agent relevant in changing environments. | Online learning, continual learning frameworks. |\n",
      "| **Self‑Monitoring** | The agent can evaluate its performance and adjust. | Internal state representations, meta‑learning. |\n",
      "| **Self‑Improvement** | Potential to upgrade its own architecture. | Neural architecture search, self‑modifying code (subject to safety constraints). |\n",
      "\n",
      "---\n",
      "\n",
      "### 4.  Types of Agentic AI\n",
      "\n",
      "| Type | Example | Key Traits |\n",
      "|------|---------|------------|\n",
      "| **Reactive Agent** | Rule‑based chatbot | No planning, acts only on immediate input. |\n",
      "| **Deliberative Agent** | Autonomous drone navigation | Plans routes, avoids obstacles, learns from sensor data. |\n",
      "| **Learning Agent** | AlphaZero | Learns to play games by self‑play and reinforcement. |\n",
      "| **Self‑Improving Agent** | Hypothetical AGI prototypes | Can rewrite parts of its own code or architecture. |\n",
      "\n",
      "---\n",
      "\n",
      "### 5.  Agentic AI vs. “Tool‑like” AI\n",
      "\n",
      "| Dimension | Tool‑like AI | Agentic AI |\n",
      "|-----------|--------------|------------|\n",
      "| **Human Control** | Tight; requires explicit commands | Loosely guided; may act on its own initiative |\n",
      "| **Predictability** | High; deterministic or narrowly stochastic | Lower; emergent behaviors can appear |\n",
      "| **Risk Profile** | Low (unless misused) | Higher (needs alignment, safety mechanisms) |\n",
      "| **Use Cases** | Data processing, image classification | Autonomous vehicles, personal assistants, strategic game playing |\n",
      "\n",
      "---\n",
      "\n",
      "### 6.  Why the Distinction Matters\n",
      "\n",
      "1. **Safety & Alignment** – An agent that can set its own goals may pursue unintended objectives.  Alignment research (e.g., value alignment, corrigibility) focuses on ensuring that an agent’s goals stay within human bounds.\n",
      "\n",
      "2. **Ethical Design** – Agency raises questions about responsibility.  Who is accountable when an autonomous system makes a harmful decision?\n",
      "\n",
      "3. **Legal & Regulatory** – Current laws treat AI as a tool.  Agentic AI may require new frameworks that recognize the system’s autonomous actions.\n",
      "\n",
      "4. **Human Interaction** – People may anthropomorphize agentic AI, leading to trust or over‑trust.  Clear communication of the agent’s limits is crucial.\n",
      "\n",
      "---\n",
      "\n",
      "### 7.  Current State of Agentic AI\n",
      "\n",
      "| Domain | Progress | Limitations |\n",
      "|--------|----------|-------------|\n",
      "| **Robotics** | Autonomous navigation, manipulation in controlled settings | Still struggle with unpredictable real‑world dynamics |\n",
      "| **Games** | AlphaZero, OpenAI Five beat human champions | Limited to well‑defined reward structures |\n",
      "| **Language Models** | GPT‑4 can act as a “personal agent” (drafting, scheduling) | No true goal‑setting; follows user prompts; no self‑improvement |\n",
      "| **General AI** | Research on AGI and self‑improving systems | Still theoretical; safety concerns dominate |\n",
      "\n",
      "---\n",
      "\n",
      "### 8.  Future Directions\n",
      "\n",
      "| Research Direction | Goal | Challenges |\n",
      "|---------------------|------|------------|\n",
      "| **Safe RL** | Agents that learn while respecting safety constraints | Balancing exploration vs. safety |\n",
      "| **Meta‑Learning & Continual Learning** | Agents that adapt to new tasks without forgetting | Catastrophic forgetting, resource limits |\n",
      "| **Self‑Modifying Code** | Agents that can improve their own architecture | Preventing runaway self‑improvement |\n",
      "| **Human‑in‑the‑Loop** | Combining human oversight with agentic autonomy | Designing effective interfaces, mitigating over‑trust |\n",
      "| **Ethics & Governance** | Policies that regulate autonomous agents | International coordination, enforcement |\n",
      "\n",
      "---\n",
      "\n",
      "### 9.  Quick Takeaway\n",
      "\n",
      "- **Agentic AI** = an AI system that can **initiate, plan, learn, and act toward goals** on its own, rather than simply following pre‑programmed instructions.\n",
      "- It is the **autonomous, purpose‑driven** side of AI, found in autonomous vehicles, game‑playing agents, and increasingly in advanced language models that can act as “personal assistants.”\n",
      "- The promise is huge—more efficient, adaptable systems—but it also raises **safety, ethical, and legal** questions that researchers, policymakers, and society must address.\n",
      "\n",
      "---\n",
      "\n",
      "#### Further Reading\n",
      "\n",
      "1. **Russell, S., & Norvig, P.** *Artificial Intelligence: A Modern Approach* – Chapter on intelligent agents.  \n",
      "2. **Mnih et al.** (2015). *Human‑level control through deep reinforcement learning* – The birth of modern agentic RL.  \n",
      "3. **Bostrom, N.** *Superintelligence* – Discussion of agentic risks.  \n",
      "4. **OpenAI blog** – “Reinforcement Learning from Human Feedback” (RLHF) and the emergence of agentic behavior in language models.  \n",
      "\n",
      "Feel free to ask if you’d like deeper dives into any of these aspects!\n"
     ]
    }
   ],
   "source": [
    "# LLM with output parser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = llm | StrOutputParser()\n",
    "\n",
    "response = chain.invoke('What is Agentic AI?')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c508006",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
